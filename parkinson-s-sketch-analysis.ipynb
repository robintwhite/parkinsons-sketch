{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, it would be a relatively easy thing to simply make this a classification problem, asking whether someone has Parkinson's or not based on their drawings. I will try this as well. \n",
    "As suggested by the author of the Kernal who I forked from, Kevin Mader, there are a couple of interesting analyses that could be performed on this dataset:\n",
    "\n",
    "1. Try and order the curves and get realistic (if possibly inaccurate) trajectories for the pen movement\n",
    "2. Quantify the pressure by looking at the thickness of the skeleton at specific points.\n",
    "3. Start to quantify the 'jigglyness' of the motion (fourier analysis of the time series?, differential motion?)\n",
    "\n",
    "Looking at the curves, this is an interesting image processing problem.\n",
    "\n",
    "TODO: Map trajectory of path, indexed labelled x, y positions for potential first to last pen movement. A* or other. Dilation grow but restricted to segmented path?\n",
    "Use this to then correlate jitteryness after plotting index vs x, y . Or measure difference in distance from prvious data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)\n",
    "plt.rcParams[\"figure.dpi\"] = 160\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "#plt.rcParams['axes.labelcolor'] = 'white'\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.util import montage as montage2d\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "data_dir = Path('../input/drawings/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Datasets\n",
    "Here we organize the datasets by directory so we can see the breakdown a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "draw_df = pd.DataFrame({'path': list(data_dir.glob('*/*/*/*.png'))})\n",
    "draw_df['img_id'] = draw_df['path'].map(lambda x: x.stem)\n",
    "draw_df['disease'] = draw_df['path'].map(lambda x: x.parent.stem)\n",
    "draw_df['validation'] = draw_df['path'].map(lambda x: x.parent.parent.stem)\n",
    "draw_df['activity'] = draw_df['path'].map(lambda x: x.parent.parent.parent.stem)\n",
    "print(draw_df.shape, 'images loaded')\n",
    "draw_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_imread(in_path, resize=True):\n",
    "    \"\"\"read images, invert and scale them\"\"\"\n",
    "    c_img = 1.0-imread(in_path, as_gray=True)\n",
    "    max_dim = np.max(c_img.shape)\n",
    "    if not resize:\n",
    "        return c_img\n",
    "    if c_img.shape==(256, 256):\n",
    "        return c_img\n",
    "    if max_dim>256:\n",
    "        big_dim = 512\n",
    "    else:\n",
    "        big_dim = 256\n",
    "        \n",
    "    out_img = np.zeros((big_dim, big_dim), dtype='float32')\n",
    "    c_offset = (big_dim-c_img.shape[0])//2\n",
    "    d_offset = c_img.shape[0]+c_offset\n",
    "    \n",
    "    e_offset = (big_dim-c_img.shape[1])//2\n",
    "    f_offset = c_img.shape[1]+e_offset\n",
    "    out_img[c_offset:d_offset, e_offset:f_offset] = c_img[:(d_offset-c_offset), :(f_offset-e_offset)]\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "for c_ax, (c_lab, c_rows) in zip(m_axs.flatten(), draw_df.groupby(['activity', 'disease'])):\n",
    "    prev_img = montage2d(np.stack([fixed_imread(x) for x in c_rows['path'].iloc[0:9]], 0))\n",
    "    c_ax.imshow(prev_img, cmap='gray')\n",
    "    c_ax.set_title(' '.join(c_lab))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter and Segment\n",
    "We can filter and segment the images in order to extract the drawings more clearly as just drawing pixels and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_yen as thresh_func\n",
    "from skimage.filters import median\n",
    "from skimage.morphology import disk, opening, diamond\n",
    "\n",
    "def read_and_thresh(in_path, resize=True):\n",
    "    c_img = fixed_imread(in_path, resize=resize)\n",
    "    c_img = (255*c_img).clip(0, 255).astype('uint8')\n",
    "    c_img = median(c_img, disk(2))\n",
    "    c_thresh = thresh_func(c_img)\n",
    "    return c_img>c_thresh\n",
    "fig, m_axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for c_ax, (c_lab, c_rows) in zip(m_axs.flatten(), draw_df.groupby(['activity', 'disease'])):\n",
    "    prev_img = montage2d(np.stack([read_and_thresh(x) for x in c_rows['path'].iloc[0:9]], 0))\n",
    "    c_ax.imshow(prev_img, cmap='gray')\n",
    "    c_ax.set_title(' '.join(c_lab))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run all images\n",
    "draw_df['thresh_img'] = draw_df['path'].map(lambda x: read_and_thresh(x, resize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(3, 3)\n",
    "for c_ax, (c_lab, c_row) in zip(m_axs.flatten(), draw_df.sample(9).iterrows()):\n",
    "    c_ax.imshow(c_row['thresh_img'], cmap='gray')\n",
    "    c_ax.set_title('{activity} {disease}'.format(**c_row))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only large enough components\n",
    "Only keep objects larger than 10% of the total activated pixels. First label each separate object in image and sum the areas for each label identified (that isn't 0). Keep the index if the count is more than 10% of the total. Perform negative sort to have the largest objects with label 1. Replace the old label number with the new ordered id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label\n",
    "from skimage.morphology import closing\n",
    "def label_sort(in_img, cutoff=0.1):\n",
    "    total_cnt = np.sum(in_img>0)\n",
    "    lab_img = label(in_img)\n",
    "    new_image = np.zeros_like(lab_img)\n",
    "    remap_index = []\n",
    "    for k in np.unique(lab_img[lab_img>0]):\n",
    "        cnt = np.sum(lab_img==k) # get area of labelled object\n",
    "        if cnt>total_cnt*cutoff:\n",
    "            remap_index+=[(k, cnt)]\n",
    "    sorted_index = sorted(remap_index, key=lambda x: -x[1]) # reverse sort - largest is first\n",
    "    for new_idx, (old_idx, idx_count) in enumerate(sorted_index, 1): #enumerate starting at id 1\n",
    "        new_image[lab_img==old_idx] = new_idx\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(3, 3)\n",
    "for c_ax, (c_lab, c_row) in zip(m_axs.flatten(), draw_df.sample(9).iterrows()):\n",
    "    clean_img = closing(label_sort(c_row['thresh_img'])>0, disk(2))\n",
    "    c_ax.imshow(clean_img, cmap='gray')\n",
    "    c_ax.set_title('{activity} {disease}'.format(**c_row))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "draw_df['clean_img'] = draw_df['thresh_img'].map(lambda x: closing(label_sort(x)>0, disk(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import skeletonize\n",
    "\n",
    "fig, m_axs = plt.subplots(3, 3)\n",
    "for c_ax, (c_lab, c_row) in zip(m_axs.flatten(), draw_df.sample(9).iterrows()):\n",
    "    skel_img = skeletonize(c_row['clean_img'])\n",
    "    skel_y, skel_x = np.where(skel_img)\n",
    "    skel_x = skel_x*1.0/skel_img.shape[1]\n",
    "    skel_y = skel_y*1.0/skel_img.shape[0]\n",
    "    \n",
    "    c_ax.plot(skel_x, skel_y, 'b.')\n",
    "    c_ax.set_title('{activity} {disease}'.format(**c_row))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to table\n",
    "We convert all of the detected skeleton points into a table and combine all of the results together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_list = []\n",
    "for _, c_row in draw_df.iterrows():\n",
    "    skel_img = skeletonize(c_row['clean_img'])\n",
    "    skel_y, skel_x = np.where(skel_img)\n",
    "    skel_x = skel_x*1.0/skel_img.shape[1]\n",
    "    skel_y = skel_y*1.0/skel_img.shape[0]\n",
    "    for x, y in zip(skel_x, skel_y):\n",
    "        d_row = dict(**{k: v for k,v in c_row.items() if len(np.shape(v))<1})\n",
    "        d_row['x'] = x\n",
    "        d_row['y'] = y\n",
    "        all_row_list += [d_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_row_df = pd.DataFrame(all_row_list)\n",
    "all_row_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show all of the drawings on the same axis\n",
    "By plotting the skeleton pixels as points and rescaling we can overlay all of the images on top of each other for better visualization. The healthy patients are significantly more consistent than the Parkinson's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 2, figsize=(30, 30), dpi=72)\n",
    "for c_ax, (c_lab, c_rows) in zip(m_axs.flatten(), all_row_df.groupby(['activity', 'disease'])):\n",
    "    for c_id, d_rows in c_rows.groupby('img_id'):\n",
    "        mean_std = np.mean([d_rows['x'].std(), d_rows['y'].std()])\n",
    "        c_ax.plot((d_rows['x']-d_rows['x'].mean())/mean_std, \n",
    "                  (d_rows['y']-d_rows['y'].mean())/mean_std, '.', label=c_id, ms=0.75)\n",
    "    c_ax.legend()\n",
    "    c_ax.set_title(' '.join(c_lab))\n",
    "    c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pen Movement Trajectories \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spiral set only first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_draw_df = draw_df[draw_df['activity'] == 'spiral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array([[1,1,1],[1,1,1],[1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 'V07PE03'\n",
    "spiral_draw_df.loc[spiral_draw_df['img_id'] == c_id]['clean_img'].values[0].shape\n",
    "#spiral_draw_df.iloc[2]['clean_img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots()\n",
    "m_axs.imshow(spiral_draw_df.loc[spiral_draw_df['img_id'] == c_id]['clean_img'].values[0])\n",
    "#m_axs.imshow(spiral_draw_df.iloc[2]['clean_img'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create skeleton for distance map to determine edge points and intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spiral_draw_df['skel_img'] = spiral_draw_df['clean_img'].map(lambda x: skeletonize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 'V07PE03'\n",
    "#a = np.where(spiral_draw_df.iloc[2]['skel_img'] == True, 1, 0)\n",
    "a = np.where(spiral_draw_df.loc[spiral_draw_df['img_id'] == c_id]['skel_img'].values[0] == True, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num Nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_nn = ndimage.convolve(a, k, mode='constant', cval=0.0)\n",
    "a_nn = a_nn * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(1,2)\n",
    "m_axs[0].imshow(a)\n",
    "m_axs[1].imshow(a_nn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots()\n",
    "plt.imshow(a_nn == 2)\n",
    "plt.title('Edges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots()\n",
    "plt.imshow(a_nn == 4)\n",
    "plt.title('Intersections')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_seg = np.where(a_nn == 4, 0, 1) * a #mask a\n",
    "a_max = label_sort(a_seg, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots()\n",
    "plt.imshow(a_max)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create single pen trajectory by removing branches and joining segments. From here we can start at the furthest distance from the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbours(in_img):\n",
    "    a = np.where(in_img == True, 1, 0)\n",
    "    a_nn = ndimage.convolve(a, k, mode='constant', cval=0.0)\n",
    "    a_nn = a_nn * a\n",
    "    return a_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#spiral_draw_df['skel_dist_img'] = spiral_draw_df['skel_img'].map(lambda x: nearest_neighbours(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process to remove branches and keep clean skeleton. Find starting point; max distance from 0,0 after mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_branches(in_img):\n",
    "    a = np.where(in_img == True, 1, 0)\n",
    "    a_nn = nearest_neighbours(in_img)\n",
    "    a_no_branches = np.where(a_nn == 4, 0, 1) * a\n",
    "    a_keep = label_sort(a_no_branches, 0.05)\n",
    "    return a_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spiral_draw_df['clean_skel_img'] = spiral_draw_df['skel_img'].map(lambda x: remove_branches(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs fixing\n",
    "def get_edges(in_img):\n",
    "    a = np.where(in_img == True, 1, 0)\n",
    "    a_nn == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_draw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaned up x,y values from spiral only and processed branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spiral_list = []\n",
    "for _, c_row in spiral_draw_df.iterrows():\n",
    "    skel_img = c_row['clean_skel_img']\n",
    "    skel_y, skel_x = np.where(skel_img)\n",
    "    skel_x = skel_x*1.0/skel_img.shape[1]\n",
    "    skel_y = skel_y*1.0/skel_img.shape[0]\n",
    "    for x, y in zip(skel_x, skel_y):\n",
    "        d_row = dict(**{k: v for k,v in c_row.items() if len(np.shape(v))<1})\n",
    "        d_row['x'] = x\n",
    "        d_row['y'] = y\n",
    "        all_spiral_list += [d_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spiral_row_df = pd.DataFrame(all_spiral_list)\n",
    "all_spiral_row_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_spiral_df = all_row_df[all_row_df['activity'] == 'spiral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift x and y\n",
    "\n",
    "for (c_lab, c_rows) in all_spiral_row_df.groupby(['disease']):\n",
    "    print(c_lab)\n",
    "    for c_id, d_rows in c_rows.groupby('img_id'):\n",
    "        #print(c_id)\n",
    "        mean_std = np.mean([d_rows['x'].std(), d_rows['y'].std()])\n",
    "        x_norm = (d_rows['x']-d_rows['x'].mean())/mean_std\n",
    "        y_norm = (d_rows['y']-d_rows['y'].mean())/mean_std\n",
    "        indices = all_spiral_row_df.loc[all_spiral_row_df['img_id']==c_id].index.values\n",
    "        #print(indices)\n",
    "        all_spiral_row_df.loc[indices, 'x_norm'] = x_norm\n",
    "        all_spiral_row_df.loc[indices, 'y_norm'] = y_norm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spiral_row_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_id = 'V10PE03'\n",
    "d_rows = all_spiral_row_df[all_spiral_row_df['img_id'] == c_id]\n",
    "fig, m_axs = plt.subplots()\n",
    "m_axs.plot((d_rows['y']-d_rows['y'].mean())/mean_std, \n",
    "              (d_rows['x']-d_rows['x'].mean())/mean_std, '.', label=c_id, ms=0.75)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
